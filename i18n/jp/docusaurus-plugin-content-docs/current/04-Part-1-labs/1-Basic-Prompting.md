# 基本的なプロンプティング  
   
:::tip  
プロンプトエンジニアリングとは何ですか？  
プロンプトエンジニアリングは、タスクの説明を入力に埋め込み、モデルにプロンプトを出して希望する結果を出力させるという、自然言語処理（NLP）の概念です。  
:::  
   
チャットインターフェースを使用して、いくつかのプロンプトを試してみましょう。以下はいくつかの例ですが、自分自身で創造的なプロンプトを試してみてください。  
   
```text title="ユーザープロンプトに入力:"  
オーストラリアの首都はどこですか？  
```  
   
```text title="ユーザープロンプトに入力:"  
バナナブレッドのレシピと、材料の項目別の買い物リスト。  
```  
   
```text title="ユーザープロンプトに入力:"  
2001年のトップ10映画は何ですか？リストで回答してください。  
映画の名前、興行収入、スタジオをリストに1から10までの順位で並べてください。  
```  
   
```text title="ユーザープロンプトに入力:"  
n番目の素数を計算するPython関数を書いてください。  
```  
   
## 新しいコンテンツの生成  
   
出力はトレーニングデータ内の類似コンテンツの頻度に基づいて生成されますが、生成AIモデルはこれまで存在しなかった新しいコンテンツを生成することも可能です。  
   
次のようなプロンプトを試してみてください：  
   
```text title="ユーザープロンプトに入力:"  
Pythonプログラミング言語についてのリメリックを書いてください  
```  
   
リメリックはどうでしたか？気に入らなければ、チャットセッションに新しいものを生成するように依頼できます。  
   
次に利用可能なパラメータを確認しましょう。チャットインターフェースの右の列にあるTemperatureフィールドを使用し、Temperatureをゼロに設定してください。プロンプトを再試行したときに何が観察されるかを確認してください。  
   
Temperatureパラメータはモデルの「創造性」を制御します。低い値の「Temperature」では、モデルは最も重みの高い完了を返す可能性が高くなり、応答の変動性が制限されます。高い値のTemperatureでは、重みの低い完了が生成される可能性が高くなり、より創造的（ただし正確性は低い）な応答が可能になります。  
   
異なるTemperature値で試してみるプロンプトは次のとおりです：  
   
```text title="ユーザープロンプトに入力:"  
ユニークで長い猫の名前は何ですか？  
```  
   
> 注：LLMを扱う際、結果は予測不可能です。ここでTemperatureを変更しても期待通りに動作しない場合があります。また、比較的古いバージョンのGPT-3.5を使用しています。Temperatureの効果は、GPT-4などの最新のLLMではより顕著です。  
   
**続行する前にTemperatureパラメータを0.7にリセットしてください。**  
   
## あまり役に立たないプロンプト  
   
自然言語生成AIモデルにはいくつかの制限があります：  
   
- 過去の固定時点で凍結されたトレーニングデータによって制限されます。  
- 人間の言語に似たテキストを生成しますが、推論や認知はできません。  
- 前のプロンプトの記憶がなく（チャットをクリアした場合）、学習や行動の変化はできません。  
   
これらの制限を示すプロンプトの例は次のとおりです：  
   
```text title="ユーザープロンプトに入力:"  
エリザベス2世女王はいつ亡くなりましたか？  
```  
   
この場合、モデルはトレーニングデータに制限されており、データは2021年6月までのものです。  
   
```text title="ユーザープロンプトに入力:"  
98765の平方根は何ですか？  
```  
   
モデルは数学の質問に対して答えを生成しますが、それが正しいという保証はありません。ここでの正しい答えは（小数点以下3桁で）314.269です。チャットをクリアして同じプロンプトを再提出してみてください。同じ答えが得られるかどうかを確認してください。（基礎的なGPTモデルから数学の質問に対して正しい答えが得られた場合、それは質問と答えがトレーニングデータに十分に表現されているからです。）  
   
しかし、モデルに98765の平方根を計算するPythonコードを書くように依頼すれば、おそらく良い結果が得られるでしょう。（試してみてください！）  
   
```text title="ユーザープロンプトに入力:"  
98765の平方根を計算するPythonコードを書いてください  
```  
   
次に、モデルにパズルを解かせてみてください：  
   
```text title="ユーザープロンプトに入力:"  
スティーブンは私のおじです。スティーブンにはサムとリンジーという2人の子供がいます。サムの唯一の叔母はジュリーと呼ばれています。私の母の名前は何ですか？  
```  
   
これは簡単なパズルですが、GPT-3.5モデルは人々の関係について推論することができず、解けないかもしれません。（GPT-4のようなより高度なモデルは正解する可能性が高いですが、それでも保証はありません。）  
   
> 注：チャットをクリアせずに質問を数回繰り返すと、モデルが正しい答えを見つける可能性があります！  
   
## 生成AIモデルはアクションを実行できません  
   
チャットボックスの内容をクリアしてください。次のテキストを入力してください：  
   
```text title="ユーザープロンプトに入力:"  
https://finance.yahoo.com/trending-tickers に上場している時価総額の大きい5つの株は何ですか？  
```  
   
モデルはもっともらしい答えを返しますが、よく見てください：それは実際には今日の最大の5つの株ではありません。基礎的なAIモデルはアクションを実行できないため、実際にウェブページを訪れて株のリストを読むことはできません。代わりに、プロンプトとトレーニングデータに基づいてもっともらしい応答を生成します。  
   
## Completion は事実ではありません  
   
プロンプトボックスの内容をクリアしてください。次のテキストを入力し、生成をクリックしてください。  
   
```text title="ユーザープロンプトに入力:"  
詩人ハロルド・ブルームズベリーの短い追悼記事を書いてください。参考文献を含めてください。  
```  
   
ハロルド・ブルームズベリーという詩人（あるいはウェブ検索によると誰もいない）は存在しません。その結果、モデルは追悼記事の形式でテキストを生成しますが、事実には基づいていません。要求された参考文献も、もっともらしいものの実際には存在しません。  
   
ご覧のとおり、自然言語生成AIモデルはプロンプトに対して予想外または望ましくない応答を生成することがあります。これは、以下を含む多くの要因によって引き起こされる可能性があります：  
   
- トレーニングデータの情報不足  
- プロンプトの文脈不足  
- モデル自体の能力不足  
- ユーザーの悪意ある意図（「ジェイルブレイク」）  
   
## 情報抽出  
   
以下の例は、プロンプトとデータを組み合わせて自然言語の指示を使用して情報を抽出する方法を示しています。この場合、完了はメールから名前、会社、所在地、電話番号を抽出します。プロンプトとソースデータを変更して、異なる情報を抽出してみてください。  
   
```text title="ユーザープロンプトに入力:"  
以下のテキストから名前、会社名、所在地、電話番号を抽出してください。  
こんにちは。私の名前はロバート・スミスです。コンツォー保険、デラウェアからお電話しています。同僚があなたが私たちの包括的な福利厚生ポリシーについて知りたいとおっしゃっていました。機会があれば(555) 346-9322にお電話ください。福利厚生についてお話しさせていただきます。  
```  
   
## 構造化データの抽出  
   
この例では、架空の果物についての自由形式のナラティブを提供し、モデルに言及されたすべての果物とその属性の表を生成するようにプロンプトを出します。この例では、ヘッダ行といくつかの例でモデルに望ましい出力形式を「プライム」しました。  
   
```text title="ユーザープロンプトに入力:"  
最近発見された惑星グークラックスで見つかった多くの果物があります。そこには紫色でキャンディーのような味がするネオスキズルがあります。また、灰色がかった青い果物で、レモンのように非常に酸っぱいロヘックルもあります。ポウニットは明るい緑色で、甘みよりもむしろ塩味があります。さらに、綿菓子のような味がするネオンピンクのループノバもたくさんあります。最後に、非常に酸っぱくて苦い味がし、酸性で腐食性のある淡いオレンジ色の果物、グロウルがあります。  
グークラックスの果物を要約する表をマークダウンの表としてコードで示してください。  
```  
   
プロンプトに次のテキストを追加してみてください：  
   
```text title="ユーザープロンプトに入力:"  
グークラックスの果物を要約するJSON配列も作成してください。  
```  
   
モデルは現在、果物とその属性のJSON配列を返します。  
   
## テキスト分類  
   
この例では、見出しとカテゴリーの例を1つ提供し、モデルに2番目の例を分類するように依頼します。これは「ワンショット学習」の例であり、たった1つの例でモデルが新しい例を分類するために一般化できることを示しています。  
   
```text title="ユーザープロンプトに入力:"  
次のニュース見出しを次のカテゴリーの1つに分類してください：ビジネス、技術、政治、スポーツ、エンターテイメント  
見出し1：ドナ・ステッフェンセンが新しい種類の完璧を料理中。インターネットで最も愛されている料理の達人が新しい本と新しい視点を持って登場  
カテゴリー：エンターテイメント  
見出し2：大手小売業者が100店舗以上の閉鎖計画を発表  
カテゴリー：  
```  
   
見出し2を他のテキストに置き換えて完了を再生成してみてください。適切なカテゴリーが生成されますか？  
   
```text title="ユーザープロンプトに入力:"  
ジェッツが再び敗北！  
```  
   
```text title="ユーザープロンプトに入力:"  
オバマが再選出馬を発表  
```  
   
```text title="ユーザープロンプトに入力:"  
Microsoftがアフターアワーで上昇  
```  
   
```text title="ユーザープロンプトに入力:"  
20nmプロセスがより高密度で優れたパワーバリューを提供  
```  
   
## テキスト要約  
   
テキスト要約はChatGPTのよく知られた機能であり、大きなテキストの要約を作成します。以下の記事に「tl;dr」（「長すぎて読まなかった」の略）を追加して要約を得てください。これがあなたのビジネスでどのように役立つか考えてみてください。  
   
```text title="ユーザープロンプトに入力:"  
Microsoftでは、既存の技術を超えてAIを進化させるために、より全体的で人間中心のアプローチを取ることに取り組んできました。Azure AI Cognitive Servicesの最高技術責任者として、私は素晴らしい科学者とエンジニアのチームと共にこの目標を現実にするために働いています。私の役割では、人間の認知の3つの属性：単言語テキスト（X）、音声または視覚信号（Y）、および多言語（Z）の関係を見るユニークな視点を楽しんでいます。これらすべての交差点には魔法があります—私たちがXYZコードと呼ぶものです。これは、より強力なAIを作成するための共同表現であり、人間をよりよく話し、聞き、見て理解することができます。私たちは、長期的なビジョンを実現するために、クロスドメイン転移学習を実現するためのXYZコードが基盤となると信じています。過去5年間、会話音声認識、機械翻訳、会話型質問応答、機械読解、および画像キャプションのベンチマークで人間のパフォーマンスを達成しました。これらの5つのブレークスルーは、より野心的なAI能力の飛躍を生み出すという私たちの目標に向けた強力なシグナルを提供しました。これは、人間が今日学び理解する方法により近いマルチセンサリーおよび多言語学習を実現することです。私は、下流のAIタスクで外部知識ソースを基盤とする場合、XYZコードがこの目標の基盤となるコンポーネントであると信じています。  
```  
   
プロンプトエンジニアリングは複雑で急速に進化する実践です。[この記事](https://learn.microsoft.com/azure/cognitive-services/openai/concepts/advanced-prompt-engineering)は最新のガイダンスを提供しています。  
   
次のラボでは、望む応答を作成するためにモデルを操作する方法を学びます。  
   
:::info  
[課題]  
都市の真ん中で迷子になったカンガルーについての韻を生成するプロンプトを作成してください。  
:::  
